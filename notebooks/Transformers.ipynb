{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:50:08.031981Z",
     "iopub.status.busy": "2025-06-02T14:50:08.031550Z",
     "iopub.status.idle": "2025-06-02T14:50:12.268662Z",
     "shell.execute_reply": "2025-06-02T14:50:12.267672Z",
     "shell.execute_reply.started": "2025-06-02T14:50:08.031911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "hn_data = pd.read_csv(r\"//media/khanhxoe/New Volume/Studying/Project_HUST/Finished Project/Impute_misvalues_hanoi.csv\", usecols=[0,1,2])\n",
    "hn_data['Date'] = hn_data['Date'].ffill()\n",
    "hn_data['Date'] = pd.to_datetime(hn_data['Date'])\n",
    "hn_data = hn_data.set_index('Date', drop= True)\n",
    "hn_data['Day'] = hn_data.index.day\n",
    "hn_data['Month'] = hn_data.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:50:12.270177Z",
     "iopub.status.busy": "2025-06-02T14:50:12.269873Z",
     "iopub.status.idle": "2025-06-02T14:50:12.346554Z",
     "shell.execute_reply": "2025-06-02T14:50:12.345497Z",
     "shell.execute_reply.started": "2025-06-02T14:50:12.270139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_dataframe_health(df):\n",
    "    print(\" Checking for NaNs...\")\n",
    "    print(df.isna().sum(), \"\\n\")\n",
    "\n",
    "    print(\" Checking for non-numeric values...\")\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            pd.to_numeric(df[col])\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Column '{col}' has non-numeric values: {e}\")\n",
    "\n",
    "    print(\"\\n Checking column data types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "\n",
    "    print(\"\\n Checking value ranges (summary stats):\")\n",
    "    print(df.describe(include='all'))\n",
    "\n",
    "    print(\"\\n Done checking.\")\n",
    "\n",
    "# Gọi hàm với DataFrame của ông\n",
    "check_dataframe_health(hn_data)\n",
    "\n",
    "def find_weird_values(df):\n",
    "    for col in df.columns:\n",
    "        weird_vals = df[col][~df[col].apply(lambda x: str(x).replace('.', '', 1).isdigit())]\n",
    "        if not weird_vals.empty:\n",
    "            print(f\"Weird values in '{col}':\")\n",
    "            print(weird_vals.unique())  # in thử vài cái thôi cho đỡ rối\n",
    "            print()\n",
    "\n",
    "find_weird_values(hn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T07:04:27.571305Z",
     "iopub.status.busy": "2025-05-31T07:04:27.570992Z",
     "iopub.status.idle": "2025-05-31T07:04:27.580299Z",
     "shell.execute_reply": "2025-05-31T07:04:27.579367Z",
     "shell.execute_reply.started": "2025-05-31T07:04:27.571278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hn_data['Hour'] = hn_data['Hour'].replace('#NUM!', 0)\n",
    "hn_data['Hour'] = hn_data['Hour'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = hn_data[(hn_data.index.year == 2017) & ((hn_data.index.month == 7)) & ((hn_data.index.day == 29))]\n",
    "plt.figure(figsize= (25, 5))\n",
    "plt.plot(sample['Waterlevel'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:50:14.548146Z",
     "iopub.status.busy": "2025-06-02T14:50:14.547852Z",
     "iopub.status.idle": "2025-06-02T14:50:14.560535Z",
     "shell.execute_reply": "2025-06-02T14:50:14.559312Z",
     "shell.execute_reply.started": "2025-06-02T14:50:14.548121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Series_Dataset(Dataset):\n",
    "    def __init__(self, data, past_len, pred_len, stride=1):\n",
    "        super(Series_Dataset, self).__init__()\n",
    "        self.past_len = past_len\n",
    "        self.pred_len = pred_len\n",
    "        self.stride = stride\n",
    "        self.df = data\n",
    "\n",
    "        self.x_values, self.y_shifted, self.y_label, self.x_times, self.y_shifted_times, self.y_label_times = \\\n",
    "            self.create_sequences_with_cores_time(self.df, self.past_len, self.pred_len)\n",
    "\n",
    "    def create_sequences_with_cores_time(\n",
    "            self, data: pd.DataFrame, \n",
    "            past_len: int, pred_len: int\n",
    "        ):\n",
    "        \n",
    "        x_values, y_shifted, y_label = [], [], []\n",
    "        x_hours, y_shifted_hours, y_label_hours = [], [], []\n",
    "        x_days, y_shifted_days, y_label_days = [], [], []\n",
    "        x_months, y_shifted_months, y_label_months = [], [], []\n",
    "\n",
    "        for i in range(0, len(data) - past_len - pred_len + 1):\n",
    "            x_seq = data.iloc[i:i + past_len]\n",
    "            y_shifted_seq = data.iloc[i+past_len-1 : i+past_len+pred_len-1]\n",
    "            y_label_seq = data.iloc[i + past_len:i + past_len + pred_len]\n",
    "\n",
    "            # Values\n",
    "            x_values.append(x_seq['Waterlevel'].values)\n",
    "            y_shifted.append(y_shifted_seq['Waterlevel'].values)\n",
    "            y_label.append(y_label_seq['Waterlevel'].values)\n",
    "\n",
    "            # Time features\n",
    "            x_hours.append(x_seq['Hour'].values)\n",
    "            y_shifted_hours.append(y_shifted_seq['Hour'].values)\n",
    "            y_label_hours.append(y_label_seq['Hour'].values)\n",
    "\n",
    "            x_days.append(x_seq['Day'].values)\n",
    "            y_shifted_days.append(y_shifted_seq['Day'].values)\n",
    "            y_label_days.append(y_label_seq['Day'].values)\n",
    "\n",
    "            x_months.append(x_seq['Month'].values)\n",
    "            y_shifted_months.append(y_shifted_seq['Month'].values)\n",
    "            y_label_months.append(y_label_seq['Month'].values)\n",
    "\n",
    "        x_values = np.array(x_values)\n",
    "        y_shifted = np.array(y_shifted)\n",
    "        y_label = np.array(y_label)\n",
    "\n",
    "        x_times = np.stack([\n",
    "            np.array(x_hours, dtype=np.int32),\n",
    "            np.array(x_days, dtype=np.int32),\n",
    "            np.array(x_months, dtype=np.int32)\n",
    "        ], axis=-1)\n",
    "\n",
    "        y_shifted_times = np.stack([\n",
    "            np.array(y_shifted_hours, dtype=np.int32),\n",
    "            np.array(y_shifted_days, dtype=np.int32),\n",
    "            np.array(y_shifted_months, dtype=np.int32)\n",
    "        ], axis=-1)\n",
    "\n",
    "        y_label_times = np.stack([\n",
    "            np.array(y_label_hours, dtype=np.int32),\n",
    "            np.array(y_label_days, dtype=np.int32),\n",
    "            np.array(y_label_months, dtype=np.int32)\n",
    "        ], axis=-1)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(x_values, dtype=torch.float32),\n",
    "            torch.tensor(y_shifted, dtype=torch.float32),\n",
    "            torch.tensor(y_label, dtype=torch.float32),\n",
    "            torch.tensor(x_times, dtype=torch.int),\n",
    "            torch.tensor(y_shifted_times, dtype=torch.int),\n",
    "            torch.tensor(y_label_times, dtype=torch.int)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_values)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_values = self.x_values[idx].unsqueeze(-1)\n",
    "        y_shifted = self.y_shifted[idx].unsqueeze(-1)\n",
    "        y_label = self.y_label[idx].unsqueeze(-1)\n",
    "        \n",
    "        x_times = self.x_times[idx]\n",
    "        y_shifted_times = self.y_shifted_times[idx]\n",
    "        y_label_times = self.y_label_times[idx]\n",
    "\n",
    "        return x_values, y_shifted, y_label, x_times, y_shifted_times, y_label_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Ha Noi & Vu Quang**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:50:17.865809Z",
     "iopub.status.busy": "2025-06-02T14:50:17.865531Z",
     "iopub.status.idle": "2025-06-02T14:50:17.880078Z",
     "shell.execute_reply": "2025-06-02T14:50:17.879233Z",
     "shell.execute_reply.started": "2025-06-02T14:50:17.865786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = hn_data.loc[(hn_data.index.year >= 2008) & (hn_data.index.year <= 2016)]\n",
    "test_data = hn_data.loc[(hn_data.index.year >= 2017) & (hn_data.index.year <= 2017)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Hung Yen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T07:04:36.262350Z",
     "iopub.status.busy": "2025-05-31T07:04:36.262035Z",
     "iopub.status.idle": "2025-05-31T07:04:36.277920Z",
     "shell.execute_reply": "2025-05-31T07:04:36.277095Z",
     "shell.execute_reply.started": "2025-05-31T07:04:36.262325Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = hn_data.loc[(hn_data.index.year >= 2008) & (hn_data.index.year <= 2013)]\n",
    "test_data = hn_data.loc[(hn_data.index.year >= 2014) & (hn_data.index.year <= 2015)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Splitting data into 2 dataset: drought dataset and flood dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:50:52.314627Z",
     "iopub.status.busy": "2025-06-02T14:50:52.314344Z",
     "iopub.status.idle": "2025-06-02T14:50:52.324372Z",
     "shell.execute_reply": "2025-06-02T14:50:52.323617Z",
     "shell.execute_reply.started": "2025-06-02T14:50:52.314605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "drought_test_data = hn_data.loc[\n",
    "    (hn_data.index.year == 2017) &\n",
    "    (\n",
    "        (hn_data.index.month >= 1) &\n",
    "        (hn_data.index.month <= 3)\n",
    "    ) \n",
    "]\n",
    "\n",
    "flood_test_data = hn_data.loc[\n",
    "    (hn_data.index.year == 2017) &\n",
    "    ((hn_data.index.month >=6) & (hn_data.index.month <=8))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data values need to be scaled due to the sensitivity of Transformer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:50:58.003451Z",
     "iopub.status.busy": "2025-06-02T14:50:58.003171Z",
     "iopub.status.idle": "2025-06-02T14:50:58.073048Z",
     "shell.execute_reply": "2025-06-02T14:50:58.072196Z",
     "shell.execute_reply.started": "2025-06-02T14:50:58.003421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_data.loc[:, 'Waterlevel'] = scaler.fit_transform(train_data[['Waterlevel']])\n",
    "test_data.loc[:, 'Waterlevel'] = scaler.transform(test_data[['Waterlevel']])\n",
    "drought_test_data.loc[:, 'Waterlevel'] = scaler.transform(drought_test_data[['Waterlevel']])\n",
    "flood_test_data.loc[:, 'Waterlevel'] = scaler.transform(flood_test_data[['Waterlevel']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng các mốc thời gian, nhúng cái mốc dữ liệu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tạo dấu mốc thời gian cho các vị trí nằm trong chuỗi dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:00.554787Z",
     "iopub.status.busy": "2025-06-02T14:51:00.554483Z",
     "iopub.status.idle": "2025-06-02T14:51:00.560534Z",
     "shell.execute_reply": "2025-06-02T14:51:00.559538Z",
     "shell.execute_reply.started": "2025-06-02T14:51:00.554761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PositionalInputEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalInputEmbedding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):  # x: [B, L, D] or [B, L, input_dim]\n",
    "        return self.pe[:, :x.size(1), :].expand(x.size(0), -1, -1)  # [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T16:43:30.609484Z",
     "iopub.status.busy": "2025-05-10T16:43:30.609200Z",
     "iopub.status.idle": "2025-05-10T16:43:30.623161Z",
     "shell.execute_reply": "2025-05-10T16:43:30.622276Z",
     "shell.execute_reply.started": "2025-05-10T16:43:30.609463Z"
    }
   },
   "outputs": [],
   "source": [
    "class ValueEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, device):\n",
    "        super(ValueEmbedding, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, d_model, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhúng các móc thời gian vào chiều không gian lớn hơn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:03.454243Z",
     "iopub.status.busy": "2025-06-02T14:51:03.453883Z",
     "iopub.status.idle": "2025-06-02T14:51:03.464928Z",
     "shell.execute_reply": "2025-06-02T14:51:03.464052Z",
     "shell.execute_reply.started": "2025-06-02T14:51:03.454217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "        \n",
    "        self.device = \"cuda\"\n",
    "        \n",
    "        self.hour_list = torch.tensor([1,4,7,10,13,16,19,22]).to(self.device)\n",
    "        self.day_list = torch.tensor(np.arange(1, 32)).to(self.device)\n",
    "        self.month_list = torch.tensor(np.arange(1, 13)).to(self.device)\n",
    "        \n",
    "        self.hour_embed = nn.Embedding(len(self.hour_list), d_model)\n",
    "        self.day_embed = nn.Embedding(len(self.day_list), d_model)\n",
    "        self.month_embed = nn.Embedding(len(self.month_list), d_model)\n",
    "\n",
    "        #init.xavier_uniform_(self.hour_embed.weight)\n",
    "        #init.xavier_uniform_(self.day_embed.weight)\n",
    "        #init.xavier_uniform_(self.month_embed.weight)\n",
    "        \n",
    "        self.hour_norm = nn.LayerNorm(d_model)\n",
    "        self.day_norm = nn.LayerNorm(d_model)\n",
    "        self.month_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.temporal_proj = nn.Linear(d_model * 2, d_model)\n",
    "\n",
    "    def forward(self, x_mark):\n",
    "        \n",
    "        x_hours = x_mark[:, :, 0].reshape(x_mark.shape[0], -1).to(self.device)\n",
    "        x_days = x_mark[:, :, 1].reshape(x_mark.shape[0], -1).to(self.device)\n",
    "        x_months = x_mark[:, :, 2].reshape(x_mark.shape[0], -1).to(self.device)\n",
    "\n",
    "        hour_indices = (x_hours.unsqueeze(-1) == self.hour_list ).float().argmax(dim=-1).to(self.device)\n",
    "        day_indices = (x_days.unsqueeze(-1) == self.day_list).float().argmax(dim=-1).to(self.device)\n",
    "        month_indices = (x_months.unsqueeze(-1) == self.month_list).float().argmax(dim=-1).to(self.device)\n",
    "\n",
    "        hour_x = self.hour_norm(self.hour_embed(hour_indices))\n",
    "        day_x = self.day_norm(self.day_embed(day_indices))\n",
    "        month_x = self.month_norm(self.month_embed(month_indices))\n",
    "        \n",
    "        out = torch.cat([day_x, month_x], dim=-1)  # shape: [B, T, 3*d_model]\n",
    "        out = self.temporal_proj(out)     \n",
    "\n",
    "        return out.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xử lý nhúng dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:09.598194Z",
     "iopub.status.busy": "2025-06-02T14:51:09.597704Z",
     "iopub.status.idle": "2025-06-02T14:51:09.605399Z",
     "shell.execute_reply": "2025-06-02T14:51:09.604283Z",
     "shell.execute_reply.started": "2025-06-02T14:51:09.598148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, device, dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        self.value_embedding = ValueEmbedding(input_dim, d_model, device= device)\n",
    "        self.position_embedding = PositionalInputEmbedding(d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.prj = nn.Linear(\n",
    "            in_features = d_model*3,\n",
    "            out_features = d_model\n",
    "        )\n",
    "        self.prj2 = nn.Linear(\n",
    "            in_features= d_model,\n",
    "            out_features= d_model\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, x_times):\n",
    "        value_emb = self.value_embedding(x)              \n",
    "        pos_emb = self.position_embedding(x)             \n",
    "        temp_emb = self.temporal_embedding(x_times)         \n",
    "        x = torch.cat([value_emb, pos_emb, temp_emb], dim=-1)\n",
    "        #x = value_emb + pos_emb + temp_emb\n",
    "        x = self.prj(x)                                        \n",
    "    \n",
    "        return self.dropout(x).to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiến trúc mô hình Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:10.851200Z",
     "iopub.status.busy": "2025-06-02T14:51:10.850847Z",
     "iopub.status.idle": "2025-06-02T14:51:10.858323Z",
     "shell.execute_reply": "2025-06-02T14:51:10.857492Z",
     "shell.execute_reply.started": "2025-06-02T14:51:10.851170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model phải chia hết cho num_heads\"\n",
    "        self.kernel_size = 7\n",
    "\n",
    "        self.conv_q = nn.Conv1d(d_model, d_model, kernel_size= self.kernel_size, padding=(self.kernel_size-1)//2, bias=False)\n",
    "        self.conv_k = nn.Conv1d(d_model, d_model, kernel_size= self.kernel_size, padding=(self.kernel_size-1)//2, bias=False)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        q = self.conv_q(query.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        k = self.conv_k(key.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        q = self.q_linear(query)\n",
    "        k = self.k_linear(key)\n",
    "        v = self.v_linear(value)\n",
    "        \n",
    "        def reshape(x):\n",
    "            return x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        q, k, v = map(reshape, (q, k, v))\n",
    "        self.scale = torch.tensor(1.0 / math.sqrt(self.d_k))\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        attn_probs = F.softmax(attn_scores, dim=-1) \n",
    "        attn_probs = self.dropout(attn_probs)\n",
    "        output = torch.matmul(attn_probs, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        return self.out_linear(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:12.135928Z",
     "iopub.status.busy": "2025-06-02T14:51:12.135653Z",
     "iopub.status.idle": "2025-06-02T14:51:12.140723Z",
     "shell.execute_reply": "2025-06-02T14:51:12.139916Z",
     "shell.execute_reply.started": "2025-06-02T14:51:12.135906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(self.relu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EncoderLayers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:13.081439Z",
     "iopub.status.busy": "2025-06-02T14:51:13.081131Z",
     "iopub.status.idle": "2025-06-02T14:51:13.087902Z",
     "shell.execute_reply": "2025-06-02T14:51:13.087063Z",
     "shell.execute_reply.started": "2025-06-02T14:51:13.081417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.kernel_size = 3\n",
    "\n",
    "        self.attn = MultiHeadAttention(\n",
    "            d_model=d_model, \n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.omega = nn.Parameter(torch.ones(1, 1, d_model))\n",
    "        nn.init.xavier_normal_(self.omega, gain=1.0)\n",
    "        self.omega2 = nn.Parameter(torch.ones(1, 1, d_model))\n",
    "        nn.init.xavier_normal_(self.omega2, gain=1.0)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        shortcut = x * self.omega\n",
    "        x = self.norm1(x)\n",
    "        attn_output = self.attn(x, x, x, mask) \n",
    "        attn_output = self.dropout(attn_output) \n",
    "        attn_output = attn_output + shortcut\n",
    "\n",
    "        shortcut2 = attn_output * self.omega2\n",
    "        attn_output = self.norm1(attn_output)\n",
    "        ffn_output = self.dropout(self.ffn(attn_output))\n",
    "        ffn_output = ffn_output + shortcut2\n",
    "        return self.norm2(ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:14.387261Z",
     "iopub.status.busy": "2025-06-02T14:51:14.386945Z",
     "iopub.status.idle": "2025-06-02T14:51:14.392811Z",
     "shell.execute_reply": "2025-06-02T14:51:14.391828Z",
     "shell.execute_reply.started": "2025-06-02T14:51:14.387238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, pred_dim, \n",
    "        d_model, num_layers,\n",
    "        num_heads, d_ff, \n",
    "        device, dropout=0.1\n",
    "        ):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embedding = DataEmbedding(pred_dim, d_model, device, dropout)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d_model, device= device)\n",
    "\n",
    "    def forward(self, x, x_times, mask=None):\n",
    "        x = self.embedding(x, x_times)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DecoderLayers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:16.059881Z",
     "iopub.status.busy": "2025-06-02T14:51:16.059608Z",
     "iopub.status.idle": "2025-06-02T14:51:16.066016Z",
     "shell.execute_reply": "2025-06-02T14:51:16.065067Z",
     "shell.execute_reply.started": "2025-06-02T14:51:16.059859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            d_model, num_heads, dropout\n",
    "        )\n",
    "        \n",
    "        self.cross_attn = MultiHeadAttention(\n",
    "            d_model, num_heads, dropout\n",
    "        )\n",
    "        \n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, tgt_mask=None, src_mask=None):\n",
    "        x_norm = self.norm1(x)\n",
    "        self_attn_output = self.self_attn(x_norm, x_norm, x_norm, tgt_mask)\n",
    "        x = x + self.dropout(self_attn_output)\n",
    "\n",
    "        x_norm = self.norm2(x)\n",
    "        cross_attn_output = self.cross_attn(x_norm, enc_output, enc_output, src_mask)\n",
    "        x = x + self.dropout(cross_attn_output)\n",
    "        \n",
    "        x_norm = self.norm3(x)\n",
    "        ffn_output = self.ffn(x_norm)\n",
    "        x = x + self.dropout(ffn_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:51:17.860041Z",
     "iopub.status.busy": "2025-06-02T14:51:17.859710Z",
     "iopub.status.idle": "2025-06-02T14:51:17.865588Z",
     "shell.execute_reply": "2025-06-02T14:51:17.864492Z",
     "shell.execute_reply.started": "2025-06-02T14:51:17.860012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tar_dim, d_model, num_layers, num_heads, d_ff, device, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = DataEmbedding(tar_dim, d_model, device, dropout)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d_model, device= device)\n",
    "\n",
    "    def forward(self, x, x_times, enc_output, tgt_mask= None, src_mask= None):\n",
    "        x = self.embedding(x, x_times)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, tgt_mask, src_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:52:58.505733Z",
     "iopub.status.busy": "2025-06-02T14:52:58.505448Z",
     "iopub.status.idle": "2025-06-02T14:52:58.515329Z",
     "shell.execute_reply": "2025-06-02T14:52:58.514553Z",
     "shell.execute_reply.started": "2025-06-02T14:52:58.505712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, pred_dim, tar_dim, device, d_model=512, num_layers=6, num_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.encoder = Encoder(pred_dim, d_model, num_layers, num_heads, d_ff, device, dropout)\n",
    "        self.decoder = Decoder(tar_dim, d_model, num_layers, num_heads, d_ff, device, dropout)\n",
    "        self.out = nn.Linear(d_model, tar_dim)\n",
    "\n",
    "    def generate_mask(self, x_values, y_values):\n",
    "        batch_size = x_values.size(0)\n",
    "        pred_len = y_values.size(1)\n",
    "\n",
    "        past_mask = None\n",
    "        pred_mask = torch.triu(\n",
    "            torch.ones((pred_len, pred_len), device=self.device), diagonal=1\n",
    "        ).bool()  \n",
    "\n",
    "        pred_mask = pred_mask.unsqueeze(0).unsqueeze(1)  # [1, 1, tgt_seq_len, tgt_seq_len]\n",
    "        pred_mask = pred_mask.expand(batch_size, 1, -1, -1)  # [batch_size, 1, tgt_seq_len, tgt_seq_len]\n",
    "\n",
    "        return past_mask, pred_mask\n",
    "    \n",
    "    def forward(self, x_values, x_times, y_shifted, y_shifted_times, past_mask=None, pred_mask=None): \n",
    "        past_mask, pred_mask = self.generate_mask(x_values, y_shifted)\n",
    "        enc_output = self.encoder(x_values, x_times, past_mask)\n",
    "        dec_output = self.decoder(y_shifted, y_shifted_times, enc_output, pred_mask, past_mask) \n",
    "        return self.out(dec_output)\n",
    "\n",
    "    def inference_reusing(self, x_values, x_times, y_label_times):\n",
    "\n",
    "        self.eval()\n",
    "        batch_size = x_values.size(0)\n",
    "        pred_len = y_label_times.size(1)\n",
    "        past_mask = None\n",
    "        y_pred = []\n",
    "\n",
    "        enc_output = self.encoder(x_values, x_times, past_mask)\n",
    "        dec_input = x_values[:, -1:, :]\n",
    "        dec_time_input = x_times[:, -1:, :]\n",
    "\n",
    "        for i in range(pred_len):\n",
    "            _, pred_mask = self.generate_mask(x_values, dec_input)\n",
    "            dec_output = self.decoder(dec_input, dec_time_input, enc_output, pred_mask, past_mask)\n",
    "            pred = self.out(dec_output)\n",
    "\n",
    "            dec_input = torch.concat([dec_input, pred[:, -1:, :]], dim=1)\n",
    "            dec_time_input = torch.concat([dec_time_input, y_label_times[:, i:i+1, :]], dim=1)\n",
    "\n",
    "        return dec_input[:, 1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 40\n",
    "pred_len = 24\n",
    "num_workers = 6\n",
    "pin_mem = True\n",
    "\n",
    "train_dataset = Series_Dataset(train_data, past_len=seq_len, pred_len=pred_len, stride=1)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=True\n",
    ")\n",
    "test_dataset = Series_Dataset(test_data, past_len=seq_len, pred_len=pred_len, stride=1)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=True\n",
    ")\n",
    "drought_dataset = Series_Dataset(drought_test_data, past_len=seq_len, pred_len=pred_len, stride=1)\n",
    "drought_loader = DataLoader(\n",
    "    drought_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem\n",
    ")\n",
    "flood_test_dataset = Series_Dataset(flood_test_data, past_len=seq_len, pred_len=pred_len, stride=1)\n",
    "flood_loader = DataLoader(\n",
    "    flood_test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the training and evaluating function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T18:00:57.938708Z",
     "iopub.status.busy": "2025-06-02T18:00:57.938489Z",
     "iopub.status.idle": "2025-06-02T18:00:57.947503Z",
     "shell.execute_reply": "2025-06-02T18:00:57.946652Z",
     "shell.execute_reply.started": "2025-06-02T18:00:57.938688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:        \n",
    "            x_values = batch[0].to(device)\n",
    "            y_shifted = batch[1].to(device)\n",
    "            y_label = batch[2].to(device)\n",
    "    \n",
    "            x_times = batch[3].to(device)\n",
    "            y_shifted_times = batch[4].to(device)\n",
    "            y_label_times = batch[5].to(device)\n",
    "\n",
    "            output = model(x_values, x_times, y_shifted, y_shifted_times) \n",
    "            loss = criterion(output.squeeze(-1), y_label.squeeze(-1))\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x_values = batch[0].to(device)\n",
    "        y_shifted = batch[1].to(device)\n",
    "        y_label = batch[2].to(device)\n",
    "\n",
    "        x_times = batch[3].to(device)\n",
    "        y_shifted_times = batch[4].to(device)\n",
    "        y_label_times = batch[5].to(device)\n",
    "\n",
    "        output = model(x_values, x_times, y_shifted, y_shifted_times) \n",
    "        loss = criterion(output.squeeze(-1), y_label.squeeze(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    return sum(epoch_losses) / len(epoch_losses)\n",
    "def fit(model, train_loader, test_loader, criterion, optimizer, num_epochs, device, scheduler=None):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        val_loss = evaluate(model, test_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if current_lr <= 5e-7:\n",
    "            return train_losses, val_losses\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | '\n",
    "              f'Train Loss: {train_loss:.6f} | '\n",
    "              f'Time: {epoch_time:.2f}s | '\n",
    "              f'Val Loss: {val_loss:.6f}')\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T18:01:00.409551Z",
     "iopub.status.busy": "2025-06-02T18:01:00.409260Z",
     "iopub.status.idle": "2025-06-02T18:01:00.461547Z",
     "shell.execute_reply": "2025-06-02T18:01:00.460856Z",
     "shell.execute_reply.started": "2025-06-02T18:01:00.409527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seq_len = 40\n",
    "pred_len = 24\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(\n",
    "    pred_dim= 1, tar_dim= 1, \n",
    "    d_model= 256, num_layers= 6, \n",
    "    num_heads= 8, d_ff= 1024, \n",
    "    device= device, dropout= 0.1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T18:01:03.810741Z",
     "iopub.status.busy": "2025-06-02T18:01:03.810398Z",
     "iopub.status.idle": "2025-06-02T18:37:47.682021Z",
     "shell.execute_reply": "2025-06-02T18:37:47.680734Z",
     "shell.execute_reply.started": "2025-06-02T18:01:03.810713Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4)\n",
    "train_losses, val_losses = fit(model, train_loader, test_loader, criterion, optimizer, num_epochs=70, device=device, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard random evaluation for recursive multi-step forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T09:37:38.451763Z",
     "iopub.status.busy": "2025-06-02T09:37:38.451432Z",
     "iopub.status.idle": "2025-06-02T09:37:38.499535Z",
     "shell.execute_reply": "2025-06-02T09:37:38.498413Z",
     "shell.execute_reply.started": "2025-06-02T09:37:38.451742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def sim_score(x, y):\n",
    "    y = np.array(y).flatten()\n",
    "    x = np.array(x).flatten()\n",
    "    \n",
    "    T = len(y)\n",
    "    diff = np.abs(y - x)\n",
    "    denom = np.max(x) - np.min(x)\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "\n",
    "    sim = np.sum(1 / (1 + (diff / denom))) / T\n",
    "    return sim\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    sim = sim_score(y_true, y_pred)\n",
    "\n",
    "    std_y = np.std(y_true)\n",
    "    std_x = np.std(y_pred)\n",
    "    fsd = 0.0 if std_y + std_x == 0 else 2 * abs(std_y - std_x) / (std_y + std_x)\n",
    "\n",
    "    return {\n",
    "        \"Sim\": sim,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"FSD\": fsd\n",
    "    }\n",
    "\n",
    "def eval_random(model, test_df, num_samples, seq_len, pred_len, device, target_scaler=None, verbose=False, top_k=None):\n",
    "    model.eval()\n",
    "    max_index = len(test_df) - seq_len - pred_len + 1 \n",
    "    \n",
    "    scores = []\n",
    "    rand_idx = np.random.randint(0, max_index, size=num_samples)    \n",
    "\n",
    "    x_values, x_times, y_label_times, y_labels = [], [], [], []\n",
    "\n",
    "    for i in rand_idx:\n",
    "        x_value = test_df.iloc[i:i+seq_len]['Waterlevel'].values\n",
    "        x_time = test_df.iloc[i:i+seq_len][['Hour', 'Day', 'Month']].values\n",
    "        y_label = test_df.iloc[i+seq_len:i+seq_len+pred_len]['Waterlevel'].values\n",
    "        y_label_time = test_df.iloc[i+seq_len:i+seq_len+pred_len][['Hour', 'Day', 'Month']].values\n",
    "\n",
    "        x_values.append(torch.tensor(x_value, dtype=torch.float32).unsqueeze(-1))\n",
    "        x_times.append(torch.tensor(x_time, dtype=torch.int))\n",
    "        y_labels.append(torch.tensor(y_label, dtype=torch.float32).unsqueeze(-1))\n",
    "        y_label_times.append(torch.tensor(y_label_time, dtype=torch.int))\n",
    "\n",
    "    x_values = torch.stack(x_values).to(device)       # [B, seq_len, 1]\n",
    "    x_times = torch.stack(x_times).to(device)         # [B, seq_len, 3]\n",
    "    y_label_times = torch.stack(y_label_times).to(device)  # [B, pred_len, 3]\n",
    "    y_labels = torch.stack(y_labels).to(device)       # [B, pred_len, 1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_preds = model.inference_reusing(x_values, x_times, y_label_times)  # [B, pred_len, 1]\n",
    "\n",
    "        y_preds_np = y_preds.cpu().numpy().reshape(num_samples * pred_len, 1)\n",
    "        y_labels_np = y_labels.cpu().numpy().reshape(num_samples * pred_len, 1)\n",
    "\n",
    "        if target_scaler:\n",
    "            y_preds_np = target_scaler.inverse_transform(y_preds_np)\n",
    "            y_labels_np = target_scaler.inverse_transform(y_labels_np)\n",
    "\n",
    "        y_preds_np = y_preds_np.reshape(num_samples, pred_len, 1)\n",
    "        y_labels_np = y_labels_np.reshape(num_samples, pred_len, 1)\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            score = compute_metrics(y_labels_np[i], y_preds_np[i])\n",
    "            score[\"index\"] = rand_idx[i]\n",
    "            scores.append(score)\n",
    "\n",
    "        scores_sorted = sorted(scores, key=lambda x: x[\"RMSE\"])\n",
    "        k = top_k if top_k else num_samples\n",
    "        top_scores = scores_sorted[:k]\n",
    "\n",
    "        return top_scores\n",
    "\n",
    "def average_scores(score_list1, score_list2):\n",
    "    assert len(score_list1) == len(score_list2), \"Hai danh sách phải có cùng số lượng mẫu\"\n",
    "\n",
    "    metrics = [\"Sim\", \"MAE\", \"RMSE\", \"R2\", \"FSD\"]\n",
    "    avg_results = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        values1 = [s[metric] for s in score_list1]\n",
    "        values2 = [s[metric] for s in score_list2]\n",
    "\n",
    "        avg_val = (np.mean(values1) + np.mean(values2)) / 2\n",
    "        avg_results[metric] = avg_val\n",
    "\n",
    "    return avg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eval samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_results1 = eval_random(\n",
    "    model, drought_test_data,\n",
    "    num_samples=20,\n",
    "    seq_len=seq_len,\n",
    "    pred_len=4,\n",
    "    device=device,\n",
    "    target_scaler=scaler,\n",
    "    verbose=True,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "top_results2 = eval_random(\n",
    "    model, flood_test_data,\n",
    "    num_samples=20,\n",
    "    seq_len=seq_len,\n",
    "    pred_len=4,\n",
    "    device=device,\n",
    "    target_scaler=scaler,\n",
    "    verbose=True,\n",
    "    top_k=10\n",
    ")\n",
    "avg_metrics = average_scores(top_results1, top_results2)\n",
    "print(\"=== Trung bình giữa 2 tập test ===\")\n",
    "print(\" \".join([f\"{value:.4f} \" for metric, value in avg_metrics.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_models_forecast(\n",
    "    models, model_names, model_types,\n",
    "    test_df, index, seq_len,\n",
    "    pred_len, device, target_scaler=None,\n",
    "    time_cols=['Hour', 'Day', 'Month'],\n",
    "    color_list=None,\n",
    "    marker_list=None\n",
    "):\n",
    "    if color_list is None:\n",
    "        color_list = ['red', 'orange', 'purple', 'brown', 'cyan', 'magenta']\n",
    "    if marker_list is None:\n",
    "        marker_list = ['o', 's', 'D', '^', 'v', '*']\n",
    "\n",
    "    x_value_raw = test_df.iloc[index:index+seq_len]['Waterlevel'].values\n",
    "    x_time = test_df.iloc[index:index+seq_len][time_cols].values\n",
    "    y_label_raw = test_df.iloc[index+seq_len:index+seq_len+pred_len]['Waterlevel'].values\n",
    "    y_label_time = test_df.iloc[index+seq_len:index+seq_len+pred_len][time_cols].values\n",
    "\n",
    "    if target_scaler is not None:\n",
    "        y_label_raw = target_scaler.inverse_transform(y_label_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "    x_times = torch.tensor(x_time, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "    y_label_times = torch.tensor(y_label_time, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    t_input = np.arange(seq_len)\n",
    "    t_pred = np.arange(0, pred_len)\n",
    "\n",
    "    if target_scaler is not None:\n",
    "        x_value_raw_plot = target_scaler.inverse_transform(x_value_raw.reshape(-1, 1)).flatten()\n",
    "    else:\n",
    "        x_value_raw_plot = x_value_raw\n",
    "\n",
    "    #plt.plot(t_input, x_value_raw_plot, label=\"Input (Past)\", color='black')\n",
    "    plt.plot(t_pred, y_label_raw, label=\"Ground Truth\", color='green')\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model_type = model_types[i]\n",
    "        model_name = model_names[i]\n",
    "        color = color_list[i % len(color_list)]\n",
    "        marker = marker_list[i % len(marker_list)]\n",
    "\n",
    "        if model_type == \"transformer\":\n",
    "            x_tensor = torch.tensor(x_value_raw, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        elif model_type == \"lstm\" or model_type == \"dlstm\":\n",
    "            if target_scaler is not None:\n",
    "                x_value = target_scaler.inverse_transform(x_value_raw.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                x_value = x_value_raw\n",
    "            x_tensor = torch.tensor(x_value, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Model type không hợp lệ: {model_type}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if model_type == \"transformer\":\n",
    "                y_pred = model.inference_reusing(x_tensor, x_times, y_label_times)\n",
    "                y_pred_np = y_pred.squeeze().cpu().numpy()\n",
    "                if target_scaler:\n",
    "                    y_pred_np = target_scaler.inverse_transform(y_pred_np.reshape(-1, 1)).flatten()\n",
    "                #plt.plot(t_pred, y_pred_np, label=model_name, color=color, marker=marker, linestyle='-', markersize=4)                    \n",
    "            \n",
    "            elif model_type == \"lstm\":\n",
    "                y_pred = model.predict_AR_multi_step_ahead(x_tensor, pred_len)\n",
    "                y_pred_np = y_pred.squeeze().cpu().numpy()\n",
    "            elif model_type == \"dlstm\":\n",
    "                y_pred = model(x_tensor)\n",
    "                y_pred_np = y_pred.squeeze().cpu().numpy()\n",
    "\n",
    "        plt.plot(t_pred, y_pred_np, label=model_name, color=color, marker=marker, linestyle='-', markersize=4)                \n",
    "\n",
    "    plt.axvline(x=seq_len-1, color='gray', linestyle=':', label='Prediction Start')\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Waterlevel\")\n",
    "    plt.ylim(0, 400)\n",
    "    plt.title(\"Multi-step Forecasting - All Models\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_multi_models_forecast(\n",
    "    models=[model1, model2, model3, model1_1, model2_1, model3_1, model4, model5, model6],\n",
    "    model_names=[\"lstm1\", \"lstm2\", \"lstm3\", \"lstm\", \"lstm\",\"lstm\",\"Trans1\", \"Trans2\", \"Trans3\"],\n",
    "    model_types=[\"lstm\", \"lstm\", \"lstm\", \"dlstm\", \"dlstm\",\"dlstm\", \"transformer\", \"transformer\", \"transformer\"],\n",
    "    test_df=drought_test_data,\n",
    "    index=100,\n",
    "    seq_len=16,\n",
    "    pred_len= 40,\n",
    "    device=device,\n",
    "    target_scaler=scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_multi_models_forecast(\n",
    "    models, model_names, model_types,\n",
    "    test_df, index, seq_len,\n",
    "    pred_len, plot_len, device, target_scaler=None,\n",
    "    time_cols=['Hour', 'Day', 'Month'],\n",
    "    color_list=None, marker_list=None,\n",
    "    random_colors=False,\n",
    "    save_path=None\n",
    "):\n",
    "    if random_colors:\n",
    "        color_list = [plt.cm.tab20(i) for i in range(len(models))]\n",
    "    elif color_list is None or len(color_list) < len(models):\n",
    "        default_colors = [\n",
    "            '#e6194b',  # Red\n",
    "            '#3cb44b',  # Green\n",
    "            \"#99b400\",  # Blue\n",
    "            \"#a85417\",  # Orange (darker)\n",
    "            \"#5e1974\",  # Purple\n",
    "            \"#1b2fa5\",  # Cyan (neon-like)\n",
    "            '#f032e6',  # Magenta\n",
    "            \"#057025\",  # Lime green\n",
    "            '#fabebe',  # Light pink\n",
    "            '#008080'   # Teal\n",
    "            ]\n",
    "\n",
    "        color_list = (default_colors * ((len(models) // len(default_colors)) + 1))[:len(models)]\n",
    "\n",
    "    if marker_list is None or len(marker_list) < len(models):\n",
    "        default_markers = ['o', 's', 'D', '^', 'v', '*', 'x', 'P', '<', '>']\n",
    "        marker_list = (default_markers * ((len(models) // len(default_markers)) + 1))[:len(models)]\n",
    "\n",
    "    # Lấy dữ liệu input và ground truth\n",
    "    x_value_raw = test_df.iloc[index:index+seq_len]['Waterlevel'].values\n",
    "    x_time = test_df.iloc[index:index+seq_len][time_cols].values\n",
    "    y_label_raw = test_df.iloc[index+seq_len:index+seq_len+pred_len]['Waterlevel'].values\n",
    "    y_label_time = test_df.iloc[index+seq_len:index+seq_len+pred_len][time_cols].values\n",
    "\n",
    "    if target_scaler is not None:\n",
    "        y_label_raw = target_scaler.inverse_transform(y_label_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "    x_times = torch.tensor(x_time, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "    y_label_times = torch.tensor(y_label_time, dtype=torch.int64).unsqueeze(0).to(device)\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    t_pred = np.arange(pred_len)\n",
    "\n",
    "    plt.plot(t_pred[:plot_len], y_label_raw[:plot_len], label=\"Ground Truth\", color='green', linewidth=2.5)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model_type = model_types[i]\n",
    "        model_name = model_names[i]\n",
    "        color = color_list[i]\n",
    "        marker = marker_list[i]\n",
    "\n",
    "        if model_type == \"transformer\":\n",
    "            x_tensor = torch.tensor(x_value_raw, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        elif model_type == \"lstm\" or model_type == \"dlstm\":\n",
    "            if target_scaler is not None:\n",
    "                x_value = target_scaler.inverse_transform(x_value_raw.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                x_value = x_value_raw\n",
    "            x_tensor = torch.tensor(x_value, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Model type không hợp lệ: {model_type}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if model_type == \"transformer\":\n",
    "                y_pred = model.inference_reusing(x_tensor, x_times, y_label_times)\n",
    "                y_pred_np = y_pred.squeeze().cpu().numpy()\n",
    "                if target_scaler:\n",
    "                    y_pred_np = target_scaler.inverse_transform(y_pred_np.reshape(-1, 1)).flatten()        \n",
    "            \n",
    "            elif model_type == \"lstm\":\n",
    "                y_pred = model.predict_AR_multi_step_ahead(x_tensor, pred_len)\n",
    "                y_pred_np = y_pred.squeeze().cpu().numpy()\n",
    "            elif model_type == \"dlstm\":\n",
    "                y_pred = model(x_tensor)\n",
    "                y_pred_np = y_pred.squeeze().cpu().numpy()\n",
    "\n",
    "        plt.plot(\n",
    "            t_pred[:plot_len],\n",
    "            y_pred_np[:plot_len],\n",
    "            label=model_name,\n",
    "            color=color,\n",
    "            marker=marker,\n",
    "            linestyle='-',\n",
    "            linewidth=1,\n",
    "            markersize=5\n",
    "        )\n",
    "\n",
    "    plt.axvline(x=0, color='gray', linestyle=':', label='Prediction Start')\n",
    "    plt.xlabel(\"Prediction Step\", fontsize=12)\n",
    "    plt.ylabel(\"Water Level\", fontsize=12)\n",
    "    plt.title(\"Multi-step Forecasting - All Models\", fontsize=16)\n",
    "    plt.legend(fontsize=10, loc='upper right')\n",
    "    plt.ylim(50, 300)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"✅ Saved figure to {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_multi_models_forecast(\n",
    "    models=[model1, model2, model3, model1_1, model2_1, model3_1, model4, model5, model6],\n",
    "    model_names=[\"direct_lstm1\", \"direct_lstm2\", \"direct_lstm3\", \"auto_lstm1\", \"auto_lstm2\",\"auto_lstm3\", \"Trans1\", \"\", \"Trans3\"],\n",
    "    model_types=[\"lstm\", \"lstm\", \"lstm\", \"dlstm\", \"dlstm\",\"dlstm\", \"transformer\", \"transformer\", \"transformer\"],\n",
    "    test_df=drought_test_data,\n",
    "    index=100,\n",
    "    seq_len=16,\n",
    "    pred_len=40,\n",
    "    plot_len= 20,\n",
    "    device=device,\n",
    "    target_scaler=scaler,\n",
    "    random_colors=False,\n",
    "    save_path=None\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6781706,
     "sourceId": 10909909,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6893251,
     "sourceId": 11062912,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
