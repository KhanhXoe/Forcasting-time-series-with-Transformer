{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "hn_data = pd.read_csv(r\"/media/khanhxoe/New Volume/Studying/Project_HUST/Finished Project/Impute_misvalues_hanoi.csv\", usecols=[0,1,2])\n",
    "hn_data['Date'] = hn_data['Date'].ffill()\n",
    "hn_data['Date'] = pd.to_datetime(hn_data['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Series_Dataset(Dataset):\n",
    "    def __init__(self, data, past_len, pred_len):\n",
    "        super(Series_Dataset, self).__init__()\n",
    "        self.past_len = past_len  # seq_len (độ dài chuỗi đầu vào)\n",
    "        self.pred_len = pred_len  # pred_len (độ dài dự báo)\n",
    "        self.df = data\n",
    "        self.X, self.y = self.create_sequences_with_cores_time(self.df, self.past_len, self.pred_len)\n",
    "\n",
    "    def create_sequences_with_cores_time(self, data: pd.DataFrame, past_len: int, pred_len: int):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - past_len - pred_len + 1):\n",
    "            X.append(data.iloc[i:i + past_len])\n",
    "            y.append(data.iloc[i + past_len:i + past_len + pred_len])\n",
    "\n",
    "        X = np.array(X)  \n",
    "        y = np.array(y)  \n",
    "        \n",
    "        return torch.tensor(X, dtype= torch.float32).clone().detach(), torch.tensor(y, dtype= torch.float32).clone().detach()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].unsqueeze(-1)  # Shape: [past_len, 1]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return x, y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phân chia kích thước cho tập huấn luyện và kiểm tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Chia dữ liệu Hà Nội****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = hn_data.loc[(hn_data['Date'].dt.year >= 2008) & (hn_data['Date'].dt.year <= 2016), 'Waterlevel']\n",
    "test_data = hn_data.loc[(hn_data['Date'].dt.year >= 2017) & (hn_data['Date'].dt.year <= 2017), 'Waterlevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dữ liệu mùa hạn (tháng 11 đến tháng 4)\n",
    "drought_test_data = hn_data.loc[\n",
    "    (hn_data['Date'].dt.year == 2017) &\n",
    "    (\n",
    "        (hn_data['Date'].dt.month >= 1) &\n",
    "        (hn_data['Date'].dt.month <= 3)\n",
    "    ),\n",
    "    'Waterlevel'\n",
    "]\n",
    "\n",
    "flood_test_data = hn_data.loc[\n",
    "    (hn_data['Date'].dt.year == 2017) &\n",
    "    (hn_data['Date'].dt.month.between(6, 8)),\n",
    "    'Waterlevel'\n",
    "]\n",
    "\"\"\"\n",
    "# Dữ liệu mùa hạn (tháng 11 đến tháng 4)\n",
    "drought_test_data = hn_data.loc[\n",
    "    (hn_data['Date'].dt.year == 2014) &\n",
    "    (\n",
    "        (hn_data['Date'].dt.month >= 1) &\n",
    "        (hn_data['Date'].dt.month <= 3)\n",
    "    ),\n",
    "    'Waterlevel'\n",
    "]\n",
    "\n",
    "flood_test_data = hn_data.loc[\n",
    "    (hn_data['Date'].dt.year == 2014) &\n",
    "    (hn_data['Date'].dt.month.between(6, 8)),\n",
    "    'Waterlevel'\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Chia dữ liệu Hưng Yên****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = hn_data.loc[(hn_data['Date'].dt.year >= 2008) & (hn_data['Date'].dt.year <= 2013), 'Waterlevel']\n",
    "test_data = hn_data.loc[(hn_data['Date'].dt.year >= 2014) & (hn_data['Date'].dt.year <= 2015), 'Waterlevel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, seq_len, tar_len, n_layers, hidden_dim=128, device='cuda'):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.seq_len = seq_len  \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1, hidden_size=hidden_dim, \n",
    "            num_layers=n_layers, batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.attention_dense = nn.Linear(seq_len, seq_len)\n",
    "        self.output_dense = nn.Linear(hidden_dim*seq_len, tar_len)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # |x| = [batch_size, seq_len, input_dim]\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        if mask is not None:\n",
    "            x = x * mask.unsqueeze(-1)  # Nhân với mask để đặt giá trị bị mask thành 0\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # |attention| = [batch_size, seq_len, seq_len]\n",
    "        attention = torch.bmm(lstm_out, lstm_out.transpose(1, 2))\n",
    "        # |attention| = [batch_size, seq_len, seq_len]\n",
    "        attention = self.attention_dense(attention)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        \n",
    "        context = torch.bmm(attention, lstm_out) # |context| = [batch_size, seq_len, hidden_dim]\n",
    "        flattened = context.reshape(batch_size, -1) # |flattened| = [batch_size, seq_len * hidden_dim]\n",
    "        output = self.output_dense(flattened) # |output| = [batch_size, tar_len=1]\n",
    "        return output\n",
    "\n",
    "    def predict_AR_multi_step_ahead(self, x, pred_len, mask=None):\n",
    "        self.eval()\n",
    "        batch_size = x.size(0)\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            current_input = x.clone() # [1, seq_len, 1].\n",
    "            for _ in range(pred_len):\n",
    "                step_output = self.forward(current_input, mask)  # [1, tar_len=1]\n",
    "                new_input = step_output[:, -1:]  # Lấy giá trị cuối cùng: [1, 1]\n",
    "                \n",
    "                new_input = new_input.unsqueeze(-1)  # [1, 1, 1]\n",
    "                current_input = torch.cat((current_input[:, 1:, :], new_input), dim=1)\n",
    "                predictions.append(step_output)\n",
    "        \n",
    "        predictions = torch.cat(predictions, dim=1)\n",
    "        \n",
    "        if predictions.size(1) > pred_len:\n",
    "            predictions = predictions[:, :pred_len]\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate(model, data_loader, criterion, device, mask=None):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            x, y = batch[:2]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, mask=None):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = batch[:2]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    return sum(epoch_losses) / len(epoch_losses)\n",
    "\n",
    "def fit(model, train_loader, test_loader, criterion, optimizer, epochs, device, mask=None, scheduler=None):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, mask)\n",
    "        val_loss = evaluate(model, test_loader, criterion, device, mask)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if current_lr <= 5e-7:\n",
    "            return train_losses, val_losses\n",
    "        print(\n",
    "            f\"Epoch: {epoch + 1}, Train loss: {train_loss:.6f}, \"\n",
    "            f\"Val loss: {val_loss:.6f}, \"\n",
    "            f\"Epoch time: {(end_time - start_time):.6f}s, \"\n",
    "            f\"Learning rate: {current_lr:.6f}\"\n",
    "        )\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seq_len = 16\n",
    "pred_len = 40\n",
    "num_workers = 6\n",
    "pin_mem = True\n",
    "\n",
    "train_dataset = Series_Dataset(train_data, past_len=seq_len, pred_len=pred_len)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=True\n",
    ")\n",
    "test_dataset = Series_Dataset(test_data, past_len=seq_len, pred_len=pred_len)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem\n",
    ")\n",
    "\n",
    "drought_dataset = Series_Dataset(drought_test_data, past_len=seq_len, pred_len=pred_len)\n",
    "drought_loader = DataLoader(\n",
    "    drought_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem\n",
    ")\n",
    "flood_test_dataset = Series_Dataset(flood_test_data, past_len=seq_len, pred_len=pred_len)\n",
    "flood_loader = DataLoader(\n",
    "    flood_test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem\n",
    ")\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
    "\n",
    "hidden_dim = 256\n",
    "n_layers = 4\n",
    "dropout = 0.1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTMAttention(\n",
    "    seq_len= seq_len, tar_len= pred_len, \n",
    "    n_layers= n_layers,\n",
    "    hidden_dim= hidden_dim\n",
    ").to(device)\n",
    "#model.load_state_dict(torch.load(rf'/media/khanhxoe/New Volume/Studying/Project_HUST/Finished Project/Code/Pretrained_Model/LSTM_direct_model/HaNoi/lstm_attention_hidden_dim=256_n_layers=4_seq=16_pred=1.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "train_losses, val_losses = fit(model, train_loader, test_loader, criterion, optimizer, epochs=50, device=device, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r\"/media/khanhxoe/New Volume/Studying/Project_HUST/Finished Project/Code/Model_Plot/lstm_attention_hidden_dim=256_n_layers=4_seq=16_pred=40.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Evaluation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly direct multi-step ahead forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score as r2\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def FSD(y, x):\n",
    "    SD_y = np.std(y, ddof=1)  \n",
    "    SD_x = np.std(x, ddof=1) \n",
    "    return 2 * abs(SD_y - SD_x) / (SD_y + SD_x)\n",
    "\n",
    "def similarity(y, x):\n",
    "    T = len(x)\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    sim_score = np.mean(1 / (1 + (np.abs(y - x) / (x_max - x_min))))\n",
    "    return sim_score\n",
    "\n",
    "def NSE(y_obs, y_pred):\n",
    "    numerator = np.sum((y_obs - y_pred) ** 2)\n",
    "    denominator = np.sum((y_obs - np.mean(y_obs)) ** 2)\n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "def evaluation_random_samples(model, test_loader, device, metrics, num_samples=1):\n",
    "    model.eval()\n",
    "    sims = []\n",
    "    maes = []\n",
    "    rmses = []\n",
    "    r2s = []\n",
    "    fsds = []\n",
    "    all_batches = list(test_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            x_batch, y_batch = random.choice(all_batches)\n",
    "            i = random.randint(0, len(x_batch) - 1)\n",
    "            x_batch, y_batch = x_batch[i:i+1, :, :], y_batch[i:i+1, :]\n",
    "            y_pred = model(x_batch.to(device))\n",
    "\n",
    "            y_pred_np = y_pred.squeeze(0).cpu().numpy()\n",
    "            y_true_np = y_batch.squeeze(0).cpu().numpy()\n",
    "            sim_score  = similarity(y_pred_np, y_true_np)\n",
    "            mae_score = mae(y_true_np, y_pred_np)\n",
    "            rmse_score = rmse(y_true_np, y_pred_np)\n",
    "            r2_score = r2(y_true_np, y_pred_np)\n",
    "            fsd_score = FSD(y_pred_np, y_true_np)\n",
    "            sims.append(sim_score)\n",
    "            maes.append(mae_score)\n",
    "            rmses.append(rmse_score)\n",
    "            r2s.append(r2_score)\n",
    "            fsds.append(fsd_score)\n",
    "\n",
    "    avg_results = {\n",
    "        \"Similarity\": np.mean(sims),\n",
    "        \"MAE\": np.mean(maes),\n",
    "        \"RMSE\": np.mean(rmses),\n",
    "        \"R2\": np.mean(r2s),\n",
    "        \"FSD\": np.mean(fsds)\n",
    "    }\n",
    "    return avg_results\n",
    "\n",
    "test_loaders = [\n",
    "    (\"test_loader_sub\", drought_loader),\n",
    "    (\"test_loader1\", flood_loader)\n",
    "]\n",
    "\n",
    "metrics = [\n",
    "    (\"Similarity\", similarity),\n",
    "    (\"MAE\", mae),\n",
    "    (\"RMSE\", rmse),\n",
    "    (\"R2\", r2),\n",
    "    (\"FSD\", FSD)\n",
    "]\n",
    "\n",
    "score1 = evaluation_random_samples(model, drought_loader, device, metrics, num_samples=20)\n",
    "score2 = evaluation_random_samples(model, flood_loader, device, metrics, num_samples=20)\n",
    "print(\"Average Scores for 2 test_loader\")\n",
    "output = \" \".join(\n",
    "    f\"{((score1[metric[0]] + score2[metric[0]]) / 2):.2f}\" for metric in metrics\n",
    ")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly recursive multi-step ahead forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score \n",
    "import math\n",
    "\n",
    "def similarity(y, x):\n",
    "    T = len(x)\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    sim_score = np.mean(1 / (1 + (np.abs(y - x) / (x_max - x_min + 1e-8))))\n",
    "    return sim_score\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r_squared = r2_score(y_true, y_pred)\n",
    "    sim = similarity(y_pred, y_true)\n",
    "\n",
    "    std_y = np.std(y_true)\n",
    "    std_x = np.std(y_pred)\n",
    "\n",
    "    if std_y + std_x == 0:\n",
    "        fsd = 0.0\n",
    "    else:\n",
    "        fsd = 2 * abs(std_y - std_x) / (std_y + std_x)\n",
    "\n",
    "    return {\n",
    "        \"Sim\": sim,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r_squared,\n",
    "        \"FSD\": fsd\n",
    "    }\n",
    "\n",
    "def eval_random_multi_step_ahead(model, test_data, past_len, pred_len, num_samples, device):\n",
    "    model.eval()\n",
    "\n",
    "    rand_idx = np.random.randint(0, len(test_data) - past_len - pred_len + 1, size=num_samples)\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for idx, i in enumerate(rand_idx):\n",
    "            x_values = test_data[i:i+past_len]\n",
    "            y_values = test_data[i+past_len:i+past_len+pred_len]\n",
    "            x_tensor = torch.tensor(x_values.to_numpy(), dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "            y_pred = model.predict_AR_multi_step_ahead(x_tensor, pred_len)\n",
    "            y_pred = y_pred.squeeze(0).cpu().numpy()\n",
    "            score = compute_metrics(y_values, y_pred)\n",
    "            scores.append(score)\n",
    "\n",
    "        result = {}\n",
    "        keys = scores[0].keys()\n",
    "        for key in keys:\n",
    "            result[key] = np.mean([score[key] for score in scores])\n",
    "        output = \" \".join(f\"{value:.4f}\" for key, value in result.items())\n",
    "        print(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "result = eval_random_multi_step_ahead(model, test_data, past_len=seq_len, pred_len=4, num_samples=20, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
